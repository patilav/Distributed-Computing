# Minutes of the Discussion on Futures 09/22

## Opening Remarks

Last time we started with a seminal paper on RPC and discussed the transformation of it to what we presently call RPC. This seems like a reasonable way to approach the development of futures. Historically, we started with futures, and then discussed something called a promise, which was very similar to a future but with types and failure handling. This eventually lead back to using futures today in big systems. Additionally, JavaScript promises exist today that have similar motivations to the async/await conventions introduced in the paper about F#, aiming to get rid of callbacks. These are similar to finagle which allow you to build up complex asynchronous interactions by making a DAG of asynchronous computation. Starting from Multilisp, how did this all develop and why?

## Discussion

A point was made that it feels like most of the ideas and innovation were done early on, and most of the focus was on how to use futures in an effective way. Not so much changed after a certain point, as the original futures paper we lacking a few features that are necessary in practice like error handling. With promises, we essentially solved some of these problems like adding types, loosening ties to hardware architecture, and using them on more than one machine.

A question was raised of how promises compared to RPC. RPC is slower compared to promises, because promises can buffer interactions, but this adds more complications, and additionally adds new operations like flush and sync to deal with some of the connection issues that can arise. A point was made that maybe our networks/systems are more reliable and quicker than before, and that this was sufficient as a programming model, as it was added to later languages like F#. It was noted that we can't assume that our networks are truly more reliable, as that is a fallacy of distributed computing.

A side point was made about how futures respond to error handling, and that there are futures being developed for genetics programming in Scala that implement exponential back off in retrying computation. This acts as a retry schedule for network failures, as failures in large cloud storage distributed systems are assumed to be transient and not lose vital data.

A point was made about learning how futures/promises are implemented in other languages. Many languages implement async/await keywords as transformations into promises and futures so you don't have to write them in a callback style. In one view async/await is basically a transformation on top of futures/promises. A counterpoint was made that this is usually imperfect, as certain things like error handling don't work perfectly, but generally you can represent one in terms of the other.

A point about the Multilisp paper being different from others was made that it was the only system in which claiming the future was implicit. In the other systems you had to turn the future into its underlying value. A counterpoint was made that this may be more limiting as it blocks when you need to use it, but the opinion was that this isn’t actually true, as having to touch/claim a future is probably more limiting. In the Finagle/Scala case. The point is around implicit unwrapping, but it was argued that explicit claiming makes you confront the possibility of failure. Similarities were drawn between functionality in Multilisp and Scala. A question was raised about the ability to cancel futures in Multilisp, and that it would be possible, but that it wasn't actually implemented in the paper. (Note: The other comparison I see here is to Oz's dataflow model, where execution waits until values are bound to continue with computations involving them, so there is no effective difference to the programmer in waiting for a binding (future-like) and unpacking the bound value.)

Another question was raised about the usefulness of having an explicit sync/block call vs. just using the future somewhere else and leaving it to the runtime. The answer is, maybe you want to wait on a main program thread for a bunch of other threads to do some work, and enforce an explicit synchronization point. Essentially you can attach some callback to the work being done on other threads. The issue was clarified as to what should be left to the language runtime semantics to determine when to wait vs. explicitly waiting and continuing when safe. Another point was made that its nicer if the programming language takes care of this for you like Finagle does, as cleaning up after threads isn't really the programmer's concern. The question was clarified to whether all blocking could be taken care of totally implicitly based on essentially whether data was used afterwards. The argument of waiting for asynchronous operations to occur, especially in the case of side-effects causing operations was brought up as an example of something that would want to be achieved with explicit synchronization. Additionally, in many runtimes, you don't really know when the program is done due to the nature of futures so blocking is the simplest way to achieve this. Oz's dataflow model somewhat accomplishes this, but again side effects lead to problems here. Essentially sending out across the network is a side effect, and you can't enforce ordering without a method of being explicit. With futures you can only enforce the interpretation of the value that comes back from the future, rather than the ordering of future side effects.

This comes back to a fundamental tension between a mechanism of explicit programmer control that the Multilisp paper argues for vs. the arguments a dataflow paper makes for these implicit dependencies that the runtime implicitly parallelizes. A lot of this becomes runtime dependent. The point was made that disks are an example of something that doesn't work as much in the dataflow model where you very much have to wait for something to happen. Ordering of side effects seems to be a fundamental problem of systems that try to implicitly handle concurrency. An open question was asked about what a Haskell-like model of ordering side effects in a dataflow program would look like.

A final question about technical reasons for using futures over callbacks was asked. The answer was essentially that futures are just a nice programmer abstraction as opposed to callbacks, which do the same thing. It was pointed out that most of these implementations described in the papers gradually add to the futures model, implementing additional features like interrupts. Callbacks probably make a lot of applications unnecessarily difficult.

A final final question about the original motivations about futures was asked, as there were no distributed systems at the time they were invented. The original paper about futures for Multilisp for example describes a single system. The motivation was parallelism without having to explicitly think about doing things in parallel. The design pattern is a largely practically motivated one and it has become the prevailing model that people find natural to reason about compared to threads or messages. The design of futures has been human-centric. It would be worth using JavaScript to demonstrate the transition from callbacks, to promises, to async/await syntax.

## Conclusion

I think some of the central defining points of the futures discussion were around the usefulness of the idea of futures as a human-centric programming model, as well as around the ability of futures to reason about side effects explicitly. I think almost all distributed systems introduce side effects, and that having an explicit method of concurrently reasoning about them via futures is a powerful idea, and a good reason that futures have stuck around. Additionally, it was interesting to see the enhancements made to handle problems that the original futures/promises model didn’t address, as well as the syntactical enhancements to make implicitly unwrapping and using future values possible.
