# Implementing Remote Procedure Calls: Analysis
Nathaniel Dempkowski

## Summary

Implementing Remote Procedure Calls describes a developed and benchmarked implementation of remote procedure calls (RPCs) for the Xerox Cedar programming environment. The goal of the implementation is to provide similar programming semantics to local procedure calls to make distributed system programming easier. The implementation consists of a few distinct parts. The main components: a database to track remote machines according to the interfaces they provide, a stub interface that actually implements a RPC library to facilitate communication across machines, and a RPC transport protocol that is created to efficiently accommodate this use case on local networks with exception handling. The paper additionally describes the efficiency of the RPC implementation comparted to local procedure calls, as well as some uses of RPC.

## Outline

The idea of a remote procedure call is not terribly complicated. Local procedure calls are well understood for transferring control and data on a single computer system, so it is not unimaginable for this concept to be extended across multiple computers. When remote procedures are called they suspend the calling environment to pass parameters over the network to the environment where the procedure will be evaluated. When the procedure finishes, it passes the results back over the network, and execution resumes in the initial calling environment. The attractive aspects of RPCs are semantics that make it easier for the programmer to develop distributed systems, relatively rapid processing, and ease of creating remote procedures from different levels of abstraction within code.

This paper describes an RPC system created for the Xerox Cedar programming environment. In the process of developing this system, the authors found that there were quite a few major issues that face designers of RPC systems. These issues include call semantics to deal with failures; semantics to deal with address containing arguments without shared address space; integration into existing programs; binding (how a caller determines the location and identity of a callee); a protocol for control and data transfer; and data integrity and security over an open network. The system described address all of these issues.

The designers of the system envisioned that most communication happens on local Ethernet, which is faster than general internet access and not overloaded.

This RPC system primarily aims to increase the ease of distributed computation. Researchers observed that communicating between programs with existing tools was a difficult task, even for experts in building these systems. They believe that existing communication mechanisms constrained the development of distributed computing systems. They hoped to remove unnecessary difficulties, and leave only fundamental difficulties of distributed systems: timing, independent failure of components, and coexisting independent execution environments. They also hoped that RPC communication would be efficient so that applications would not be built around avoiding communication. Additionally, they wanted communication to be secure end-to-end.

The programming model implemented for RPC is relatively straightforward. It describes a client stub and a server stub, which implement a common interface and utilize a RPCRuntime package for communications across machines. This interface can then be used almost exactly as if it existed on the client machine, with the only additional requirement being another exception to handle to account for network issues. This stub is automatically generated, from a Mesa interface, allowing for compile time type checking on the client and server. This eliminates the need for the programmer to write networking code, and allows them to use a common programming paradigm they are already used to by programming distributed systems essentially as if they were local.

An important part of an RPC implementation is how the client locates a server implementation to bind to. In this one, a caller can specify a type (interface) and instance (implementer) to bind to. This combined name is then used to locate an exporter in a database containing all server implementations of interfaces and their network addresses. A client can bind to an interface type, a specific implementation of an interface, or a specific network address. Only the interface type is required, and if other information is not specified, the closest running exporter is chosen. This centralized database allows for discovery of implementations without having to know network addresses in the client. Additionally, it provides a basic security mechanism, by only allowing authorized users to connect to the database, so that a client can know they are not going to connect to an unauthorized implementation. This dynamic discovery of machines also allows for more open-ended multi-machine algorithms.

Another extensive section of this paper was devoted to the design of a packet-level transport protocol specifically for RPC. The detailed protocol description is best left to the paper, but the authors claim that substantial performance gains can be made by implementing a protocol specifically for RPC, as it generally doesn't involve bulk data transfer and they can avoid handshake costs for setting up and taking down connections. The protocol essentially sends procedure calls requests sequentially, and expects an acknowledgement with results of every procedure call. If results are not returned within a certain time period, an acknowledgement is requested to verify that computation is ongoing. There is no timeout, similar to local procedure calls, and the protocol implements back off up to 5-minute intervals while awaiting results.

This RPC implementation also avoids expensive process swaps on server machines by reusing processes to handle subsequent RPC calls. A client is allowed to specify a specific process ID to handle their request, but if that ID is not found or busy, the RPC server simply uses an already available process to handle the request. In general no processes are created for a simple call and few (usually 4) process swaps are made.

For security, the RPC package uses DES for end to end encryption of calls.

This implementation was measured by the authors to be quite performant. Compared to local procedure calls it absolutely is not, as a simple procedure call with no arguments/results goes from 9 μs to 1059 μs.  One would assume that most of the performance cost is in transmission overhead (both network latency and library overhead to coordinate transmission), and that for longer running processes this time would be mitigated entirely. Also, 1 ms of overhead is not terrible, though it would be a consideration that would determine what types of calls should be made remotely vs. locally. This suggests that not everything is a good candidate for RPC. RPCs certainly aren't free, but they are relatively performant.

This implementation has been tested in Xerox for several projects, like a file server, Ethernet-based telephone and audio, and network games. The clients have found the RPC package convenient to use, and it has been implemented in other languages/programming environments.

## Limitations and Extensions

Some of the limitations of this system are pretty clear, especially due to the nature of networked computing. There is a fundamental limitation to the minimum latency between computers, which is much higher than the latency that can be achieved on a single computer for a procedure call. This alone is not particularly interesting, but taking a modern view where distributed systems may be located around the world to increase reliability or decrease local latency, I think that the authors could make further efforts to reduce single packet round trips. This protocol limitation is put into perspective when we consider from networking fundamentals that with a single packet requiring a RTT to ACK before sending the next one, the utilization of a high-bandwidth connection is extremely low. They claimed to address this by saturating pipes with many RPCs, but it seems unlikely that a network pipe would be saturated by requests before the CPU of the corresponding machine was saturated by workload, especially with increased bandwidth capacity.

Another aspect is that all of the processing for RPC's was sequential, pausing execution to wait for network IO and remote computation. Since this paper was written, we've heavily used asynchronous communication to optimize applications that depend on network IO. This is clearly a more optimal strategy that an RPC implementation would have to use to be competitive with things like today's standard HTTP clients. This along with "time travel" RPC where you essentially chain RPC calls as you would with promises are obvious implementations of asynchronous programming models on top of RPC for efficiency.

## Opinion

I think the ideas in this paper are high-quality and high-impact. They build on previous PRC papers, but also face the challenges that inevitably arise when going from theorizing about something to implementing it. The RPC system proposed seems like it accomplishes the author's goals, and it seems like a practical and imaginable one that could be in use in a language like Java today.

The idea of binding over interfaces still seems like a valuable foundation, even if it does have some drawbacks that were unexplored like tight client-server implementation coupling. It seems like a good start on the question of "How do we make programming networked computers like programming a single computer?", regardless of whether the question is worth asking. This idea seems to have been successful in making distributed systems programming easier in the 1980s and it doesn't seem like a model that has aged too poorly. I am sure that binding mechanisms and protocol formats would have changed over the years. An argument could also be made that protocols like HTTP or something that allows for message passing rather than procedure calls provide looser coupling and a better level of abstraction for connecting systems.

It would be interesting to see a 30-year retrospective on the ideas of this paper from someone who has a lot of experience in distributed systems and RPC. I know that RPC is still in use today in similar fashion to that described in the paper. It would be valuable to see what features have been dropped entirely, how far performance has been pushed, and what improvements have been made. I would also be interested in seeing the world of alternatives that have been explored.
